---
# Crawler Command & Control Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: crawler-controller
  labels:
    app: crawler
    component: controller
spec:
  replicas: 1  # Only need one command & control instance
  selector:
    matchLabels:
      app: crawler
      component: controller
  template:
    metadata:
      labels:
        app: crawler
        component: controller
    spec:
      serviceAccountName: crawler-service-account  # For Kubernetes API access
      containers:
      - name: controller
        image: crawler:latest  # Replace with your registry/image:tag
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
          name: http
        resources:
          limits:
            cpu: "1"
            memory: "1Gi"
          requests:
            cpu: "500m"
            memory: "512Mi"
        env:
        - name: REDIS_URL
          value: "redis://redis-service:6379"
        - name: MONGODB_URL
          value: "mongodb://mongodb-service:27017"
        - name: POSTGRES_URL
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: postgres-url
        - name: BROWSER_SERVICE_URL
          value: "http://browser-service:5000"
        - name: RUST_LOG
          value: "info,crawler=debug"
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
        livenessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 5
          periodSeconds: 10
      volumes:
      - name: config-volume
        configMap:
          name: crawler-config
---
# Browser Service Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: browser-service
  labels:
    app: crawler
    component: browser-service
spec:
  replicas: 3  # Scale this based on your needs
  selector:
    matchLabels:
      app: crawler
      component: browser-service
  template:
    metadata:
      labels:
        app: crawler
        component: browser-service
    spec:
      containers:
      - name: browser-service
        image: crawler-browser-service:latest  # Replace with your registry/image:tag
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 5000
          name: http
        resources:
          limits:
            cpu: "2"
            memory: "2Gi"
          requests:
            cpu: "500m"
            memory: "1Gi"
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
        - name: HEADLESS
          value: "true"
        volumeMounts:
        - name: scripts-volume
          mountPath: /app/scripts
        - name: shm-volume
          mountPath: /dev/shm
        livenessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 5
          periodSeconds: 10
      volumes:
      - name: scripts-volume
        emptyDir: {}
      - name: shm-volume
        emptyDir:
          medium: Memory
---
# Crawler Controller Service
apiVersion: v1
kind: Service
metadata:
  name: crawler-controller-service
  labels:
    app: crawler
    component: controller
spec:
  selector:
    app: crawler
    component: controller
  ports:
  - port: 8080
    targetPort: 8080
    name: http
  type: ClusterIP
---
# Browser Service
apiVersion: v1
kind: Service
metadata:
  name: browser-service
  labels:
    app: crawler
    component: browser-service
spec:
  selector:
    app: crawler
    component: browser-service
  ports:
  - port: 5000
    targetPort: 5000
    name: http
  type: ClusterIP
---
# HorizontalPodAutoscaler for Browser Service
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: browser-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: browser-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 70
---
# ConfigMap for configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: crawler-config
data:
  default.yaml: |
    crawler:
      max_depth: 3
      max_pages: 1000
      politeness_delay: 2000
      respect_robots_txt: true
      allowed_domains: []
      url_patterns:
        include: []
        exclude:
          - "^.*\\.(jpg|jpeg|png|gif|css|js)$"
      user_agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    
    browser:
      browser_type: "chrome"
      headless: true
      viewport:
        width: 1920
        height: 1080
        device_scale_factor: 1.0
      fingerprints:
        - name: "windows_chrome"
          user_agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
          accept_language: "en-US,en;q=0.9"
          platform: "Win32"
          extra_headers: {}
        - name: "mac_safari"
          user_agent: "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Safari/605.1.15"
          accept_language: "en-US,en;q=0.9"
          platform: "MacIntel"
          extra_headers: {}
      behavior:
        scroll_behavior: "random"
        click_delay: [100, 300]
        typing_speed: [50, 150]
        mouse_movement: true
        session_duration: [300, 1800]
    
    storage:
      queue:
        redis_url: "redis://redis-service:6379"
        task_ttl: 86400
      raw_data:
        storage_type: "mongodb"
        connection_string: "mongodb://mongodb-service:27017"
        database_name: "crawler"
        collection_prefix: "raw"
      processed_data:
        storage_type: "postgresql"
        connection_string: "postgresql://postgres:postgres@postgres-service:5432/crawler"
        schema_name: "public"
        table_prefix: "crawled"
---
# Secret for database credentials 
apiVersion: v1
kind: Secret
metadata:
  name: db-credentials
type: Opaque
stringData:
  postgres-url: "postgresql://postgres:postgres@postgres-service:5432/crawler"